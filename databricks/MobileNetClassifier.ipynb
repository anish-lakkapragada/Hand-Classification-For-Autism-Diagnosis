{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2114f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Code for databricks, to demo the model. \n",
    "\n",
    "(CPU Version tho for the broke bois)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, f1_score\n",
    "print(tf.__version__)\n",
    "\n",
    "IMAGE_SIZE = (224, 224, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8641950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_2():\n",
    "    def build_convnet(shape=None):\n",
    "        momentum = 0.9\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Conv2D(64, (3,3), input_shape=shape[1:], padding='same', activation='linear'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(momentum=momentum))\n",
    "        model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "        model.add(tf.keras.layers.MaxPool2D())\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='linear'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(momentum=momentum))\n",
    "        model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "        model.add(tf.keras.layers.MaxPool2D())\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='linear'))\n",
    "        model.add(tf.keras.layers.BatchNormalization(momentum=momentum))\n",
    "        model.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "        # flatten\n",
    "        model.add(tf.keras.layers.GlobalMaxPool2D())\n",
    "        return model\n",
    "    shape = (90, IMAGE_SIZE[0], IMAGE_SIZE[1], IMAGE_SIZE[2])\n",
    "    print('Train data shape: ', shape)\n",
    "\n",
    "    convnet = build_convnet(shape)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.TimeDistributed(convnet, input_shape=shape))\n",
    "    model.add(tf.keras.layers.LSTM(64))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(.5))\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(.5))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(.5))\n",
    "    model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab7a3a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(): \n",
    "    inp =  tf.keras.layers.Input((None, IMAGE_SIZE[0], IMAGE_SIZE[1], IMAGE_SIZE[2])) # , ragged=True\n",
    "    \n",
    "    mobilenet_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "        include_top=False, weights='imagenet', pooling='max', classes=2, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)\n",
    "    )\n",
    "    \n",
    "    for k,v in mobilenet_model._get_trainable_state().items():\n",
    "        k.trainable = False\n",
    "    \n",
    "    x = tf.keras.layers.TimeDistributed(mobilenet_model)(inp)\n",
    "    x = tf.keras.layers.LSTM(64, return_sequences=False)(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    out = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.Model(inp, out)\n",
    "\n",
    "    model.compile(loss = tf.keras.losses.BinaryCrossentropy(), optimizer = tf.keras.optimizers.Adam(learning_rate=0.01), metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01cdeb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD:::  {'train': ['_48.mp4', '_61.mp4', '_71.mp4', '_10.mp4', '_17.mp4', '_101.mp4', '_65.mp4', '_66.mp4', '_6.mp4', '_49.mp4', '_63.mp4', '_89.mp4', '_76.mp4', '_14.mp4', '_111.mp4', '_114.mp4', '_99.mp4', '_72.mp4', '_3.mp4', '_106.mp4', '_110.mp4', '_77.mp4', '_115.mp4', '_13.mp4', '_12.mp4', '_5.mp4', '_107.mp4', '_105.mp4', '_11.mp4', '_64.mp4', '_75.mp4', '_74.mp4', '_1.mp4', '_16.mp4', '_100.mp4', '_7.mp4', '_88.mp4', '_60.mp4', '_112.mp4', '_102.mp4', '_166.mp4', '_173.mp4', '_138.mp4', '_144.mp4', '_130.mp4', '_140.mp4', '_163.mp4', '_162.mp4', '_154.mp4', '_172.mp4', '_175.mp4', '_165.mp4', '_164.mp4', '_120.mp4', '_124.mp4', '_142.mp4', '_160.mp4', '_174.mp4', '_153.mp4', '_134.mp4', '_128.mp4', '_159.mp4', '_169.mp4', '_143.mp4', '_157.mp4', '_156.mp4', '_137.mp4', '_118.mp4', '_178.mp4', '_176.mp4', '_167.mp4', '_170.mp4', '_116.mp4', '_119.mp4', '_181.mp4', '_179.mp4', '_171.mp4', '_158.mp4', '_152.mp4', '_186.mp4'], 'test': ['_2.mp4', '_29.mp4', '_98.mp4', '_104.mp4', '_38.mp4', '_39.mp4', '_113.mp4', '_0.mp4', '_4.mp4', '_28.mp4', '_126.mp4', '_122.mp4', '_161.mp4', '_129.mp4', '_151.mp4', '_187.mp4', '_127.mp4', '_132.mp4', '_180.mp4', '_136.mp4']}\n",
      "(80, 90, 224, 224, 3) (20, 90, 224, 224, 3) (80,) (20,)\n"
     ]
    }
   ],
   "source": [
    "with open(\"../file_names_folds.pkl\", 'rb') as f: \n",
    "    SEEDS, FOLD_FILES = pickle.load(f)\n",
    "\n",
    "# train the model\n",
    "\n",
    "fold = FOLD_FILES[0]\n",
    "\n",
    "print('FOLD::: ', fold)\n",
    "\n",
    "train_files = [a.strip('_') for a in fold['train']]\n",
    "test_files = [a.strip('_') for a in fold['test']]\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "for filename in train_files:\n",
    "    filename_int = int(filename.split('.mp4')[0])\n",
    "\n",
    "    if filename_int <= 115:\n",
    "        curr_y = 1\n",
    "        subdir_name = 'armflapping'\n",
    "    else:\n",
    "        curr_y = 0\n",
    "        subdir_name = 'control'\n",
    "\n",
    "    curr_x = []\n",
    "    for frame in os.listdir('../behavior_data/' + subdir_name + '/' + filename):\n",
    "\n",
    "        frame_num = int(frame.split('.')[0])\n",
    "        if frame_num > 90:\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread('../behavior_data/' + subdir_name + '/' + filename + '/' + frame)\n",
    "        try:\n",
    "            image = image.reshape((image.shape[0], image.shape[1], image.shape[2]))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        curr_x.append(image)\n",
    "\n",
    "    len_data = len(os.listdir('../behavior_data/' + subdir_name + '/' + filename))\n",
    "    if len_data < 90:\n",
    "        for abc in range(len_data, 90):\n",
    "            curr_x.append(np.zeros((224, 224, 3)))\n",
    "\n",
    "    curr_x = np.array(curr_x)\n",
    "\n",
    "    X_train.append(curr_x)\n",
    "    y_train.append(curr_y)\n",
    "\n",
    "for filename in test_files:\n",
    "    filename_int = int(filename.split('.mp4')[0])\n",
    "\n",
    "    if filename_int <= 115:\n",
    "        curr_y = 1\n",
    "        subdir_name = 'armflapping'\n",
    "    else:\n",
    "        curr_y = 0\n",
    "        subdir_name = 'control'\n",
    "\n",
    "    curr_x = []\n",
    "    for frame in os.listdir('../behavior_data/' + subdir_name + '/' + filename):\n",
    "\n",
    "        frame_num = int(frame.split('.')[0])\n",
    "        if frame_num > 90:\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread('../behavior_data/' + subdir_name + '/' + filename + '/' + frame)\n",
    "        try:\n",
    "            image = image.reshape((image.shape[0], image.shape[1], image.shape[2]))\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        curr_x.append(image)\n",
    "\n",
    "    len_data = len(os.listdir('../behavior_data/' + subdir_name + '/' + filename))\n",
    "    if len_data < 90:\n",
    "        for abc in range(len_data, 90):\n",
    "            curr_x.append(np.zeros((224, 224, 3)))\n",
    "\n",
    "    curr_x = np.array(curr_x)\n",
    "\n",
    "    X_test.append(curr_x)\n",
    "    y_test.append(curr_y)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6765aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-02 11:04:43.373187: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "5/5 [==============================] - 130s 22s/step - loss: 0.7520 - accuracy: 0.5000 - precision: 0.5000 - recall: 0.6750 - val_loss: 0.6367 - val_accuracy: 0.7000 - val_precision: 0.6250 - val_recall: 1.0000\n",
      "Epoch 2/60\n",
      "5/5 [==============================] - 99s 19s/step - loss: 0.6002 - accuracy: 0.7125 - precision: 0.6977 - recall: 0.7500 - val_loss: 0.5405 - val_accuracy: 0.7000 - val_precision: 0.6250 - val_recall: 1.0000\n",
      "Epoch 3/60\n",
      "5/5 [==============================] - 85s 18s/step - loss: 0.5758 - accuracy: 0.7375 - precision: 0.7209 - recall: 0.7750 - val_loss: 0.5057 - val_accuracy: 0.7500 - val_precision: 0.6667 - val_recall: 1.0000\n",
      "Epoch 4/60\n",
      "5/5 [==============================] - 82s 17s/step - loss: 0.4992 - accuracy: 0.7625 - precision: 0.7692 - recall: 0.7500 - val_loss: 0.4974 - val_accuracy: 0.8000 - val_precision: 0.7143 - val_recall: 1.0000\n",
      "Epoch 5/60\n",
      "5/5 [==============================] - 89s 19s/step - loss: 0.5080 - accuracy: 0.7375 - precision: 0.7436 - recall: 0.7250 - val_loss: 0.4740 - val_accuracy: 0.8000 - val_precision: 0.7143 - val_recall: 1.0000\n",
      "Epoch 6/60\n",
      "5/5 [==============================] - 84s 17s/step - loss: 0.4977 - accuracy: 0.7750 - precision: 0.8438 - recall: 0.6750 - val_loss: 0.4592 - val_accuracy: 0.8000 - val_precision: 0.7143 - val_recall: 1.0000\n",
      "Epoch 7/60\n",
      "5/5 [==============================] - 81s 17s/step - loss: 0.4825 - accuracy: 0.8125 - precision: 0.8205 - recall: 0.8000 - val_loss: 0.4672 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 8/60\n",
      "5/5 [==============================] - 83s 17s/step - loss: 0.4586 - accuracy: 0.8000 - precision: 0.8000 - recall: 0.8000 - val_loss: 0.4552 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 9/60\n",
      "5/5 [==============================] - 81s 17s/step - loss: 0.4250 - accuracy: 0.8500 - precision: 0.8684 - recall: 0.8250 - val_loss: 0.4484 - val_accuracy: 0.8500 - val_precision: 0.8182 - val_recall: 0.9000\n",
      "Epoch 10/60\n",
      "5/5 [==============================] - 81s 17s/step - loss: 0.4249 - accuracy: 0.8750 - precision: 0.9167 - recall: 0.8250 - val_loss: 0.4341 - val_accuracy: 0.8000 - val_precision: 0.7500 - val_recall: 0.9000\n",
      "Epoch 11/60\n",
      "5/5 [==============================] - 81s 17s/step - loss: 0.4218 - accuracy: 0.8500 - precision: 0.8684 - recall: 0.8250 - val_loss: 0.4088 - val_accuracy: 0.8000 - val_precision: 0.7500 - val_recall: 0.9000\n",
      "Epoch 12/60\n",
      "5/5 [==============================] - 83s 17s/step - loss: 0.3728 - accuracy: 0.8750 - precision: 0.9167 - recall: 0.8250 - val_loss: 0.4179 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 13/60\n",
      "5/5 [==============================] - 82s 17s/step - loss: 0.3464 - accuracy: 0.8750 - precision: 0.8750 - recall: 0.8750 - val_loss: 0.4173 - val_accuracy: 0.8000 - val_precision: 0.7143 - val_recall: 1.0000\n",
      "Epoch 14/60\n",
      "5/5 [==============================] - 87s 18s/step - loss: 0.3675 - accuracy: 0.8750 - precision: 0.9167 - recall: 0.8250 - val_loss: 0.4171 - val_accuracy: 0.8000 - val_precision: 0.7143 - val_recall: 1.0000\n",
      "Epoch 15/60\n",
      "5/5 [==============================] - 84s 18s/step - loss: 0.3460 - accuracy: 0.8625 - precision: 0.8919 - recall: 0.8250 - val_loss: 0.3926 - val_accuracy: 0.8000 - val_precision: 0.7143 - val_recall: 1.0000\n",
      "Epoch 16/60\n",
      "5/5 [==============================] - 84s 18s/step - loss: 0.3245 - accuracy: 0.8625 - precision: 0.9394 - recall: 0.7750 - val_loss: 0.3493 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 17/60\n",
      "5/5 [==============================] - 88s 18s/step - loss: 0.2927 - accuracy: 0.8875 - precision: 0.9429 - recall: 0.8250 - val_loss: 0.3386 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 18/60\n",
      "5/5 [==============================] - 81s 17s/step - loss: 0.3144 - accuracy: 0.8875 - precision: 0.9429 - recall: 0.8250 - val_loss: 0.3464 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 19/60\n",
      "5/5 [==============================] - 83s 17s/step - loss: 0.3094 - accuracy: 0.8750 - precision: 0.9412 - recall: 0.8000 - val_loss: 0.3402 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 20/60\n",
      "5/5 [==============================] - 83s 17s/step - loss: 0.2844 - accuracy: 0.9000 - precision: 0.9444 - recall: 0.8500 - val_loss: 0.3294 - val_accuracy: 0.8500 - val_precision: 0.8182 - val_recall: 0.9000\n",
      "Epoch 21/60\n",
      "5/5 [==============================] - 84s 17s/step - loss: 0.2722 - accuracy: 0.9125 - precision: 0.9459 - recall: 0.8750 - val_loss: 0.3427 - val_accuracy: 0.8500 - val_precision: 0.8182 - val_recall: 0.9000\n",
      "Epoch 22/60\n",
      "5/5 [==============================] - 82s 17s/step - loss: 0.2799 - accuracy: 0.9250 - precision: 0.9474 - recall: 0.9000 - val_loss: 0.3486 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 23/60\n",
      "5/5 [==============================] - 80s 17s/step - loss: 0.2735 - accuracy: 0.9000 - precision: 0.9706 - recall: 0.8250 - val_loss: 0.3464 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 24/60\n",
      "5/5 [==============================] - 81s 17s/step - loss: 0.2505 - accuracy: 0.9125 - precision: 0.9231 - recall: 0.9000 - val_loss: 0.3244 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 25/60\n",
      "5/5 [==============================] - 82s 17s/step - loss: 0.2637 - accuracy: 0.9125 - precision: 0.9714 - recall: 0.8500 - val_loss: 0.3172 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 26/60\n",
      "5/5 [==============================] - 83s 17s/step - loss: 0.2387 - accuracy: 0.8750 - precision: 0.9412 - recall: 0.8000 - val_loss: 0.3324 - val_accuracy: 0.8500 - val_precision: 0.8182 - val_recall: 0.9000\n",
      "Epoch 27/60\n",
      "5/5 [==============================] - 84s 18s/step - loss: 0.2557 - accuracy: 0.9250 - precision: 0.9722 - recall: 0.8750 - val_loss: 0.3360 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 28/60\n",
      "5/5 [==============================] - 86s 18s/step - loss: 0.2300 - accuracy: 0.9250 - precision: 0.9474 - recall: 0.9000 - val_loss: 0.3283 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 29/60\n",
      "5/5 [==============================] - 81s 17s/step - loss: 0.2428 - accuracy: 0.9250 - precision: 0.9722 - recall: 0.8750 - val_loss: 0.3011 - val_accuracy: 0.8500 - val_precision: 0.8182 - val_recall: 0.9000\n",
      "Epoch 30/60\n",
      "5/5 [==============================] - 88s 19s/step - loss: 0.2124 - accuracy: 0.9250 - precision: 0.9474 - recall: 0.9000 - val_loss: 0.3022 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 31/60\n",
      "5/5 [==============================] - 84s 17s/step - loss: 0.2446 - accuracy: 0.9375 - precision: 1.0000 - recall: 0.8750 - val_loss: 0.3077 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 32/60\n",
      "5/5 [==============================] - 85s 18s/step - loss: 0.2004 - accuracy: 0.9375 - precision: 1.0000 - recall: 0.8750 - val_loss: 0.3238 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 33/60\n",
      "5/5 [==============================] - 80s 16s/step - loss: 0.2316 - accuracy: 0.9250 - precision: 0.9722 - recall: 0.8750 - val_loss: 0.3255 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 34/60\n",
      "5/5 [==============================] - 79s 17s/step - loss: 0.2370 - accuracy: 0.9000 - precision: 0.9000 - recall: 0.9000 - val_loss: 0.3157 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 35/60\n",
      "5/5 [==============================] - 78s 16s/step - loss: 0.1995 - accuracy: 0.9500 - precision: 1.0000 - recall: 0.9000 - val_loss: 0.3147 - val_accuracy: 0.8000 - val_precision: 0.7500 - val_recall: 0.9000\n",
      "Epoch 36/60\n",
      "5/5 [==============================] - 78s 16s/step - loss: 0.1980 - accuracy: 0.9250 - precision: 0.9474 - recall: 0.9000 - val_loss: 0.3054 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 37/60\n",
      "5/5 [==============================] - 78s 16s/step - loss: 0.1942 - accuracy: 0.9500 - precision: 1.0000 - recall: 0.9000 - val_loss: 0.3167 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 38/60\n",
      "5/5 [==============================] - 78s 16s/step - loss: 0.1950 - accuracy: 0.9125 - precision: 1.0000 - recall: 0.8250 - val_loss: 0.3194 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 39/60\n",
      "5/5 [==============================] - 78s 16s/step - loss: 0.2141 - accuracy: 0.9375 - precision: 1.0000 - recall: 0.8750 - val_loss: 0.3349 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 40/60\n",
      "5/5 [==============================] - 78s 16s/step - loss: 0.1888 - accuracy: 0.9375 - precision: 1.0000 - recall: 0.8750 - val_loss: 0.3287 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 41/60\n",
      "5/5 [==============================] - 78s 16s/step - loss: 0.2333 - accuracy: 0.8750 - precision: 0.9167 - recall: 0.8250 - val_loss: 0.3073 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 42/60\n",
      "5/5 [==============================] - 78s 16s/step - loss: 0.1900 - accuracy: 0.9250 - precision: 1.0000 - recall: 0.8500 - val_loss: 0.3105 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 43/60\n",
      "5/5 [==============================] - 78s 16s/step - loss: 0.2192 - accuracy: 0.9250 - precision: 0.9722 - recall: 0.8750 - val_loss: 0.3049 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 44/60\n",
      "5/5 [==============================] - 78s 16s/step - loss: 0.1946 - accuracy: 0.9250 - precision: 1.0000 - recall: 0.8500 - val_loss: 0.3057 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 45/60\n",
      "5/5 [==============================] - 97s 20s/step - loss: 0.2220 - accuracy: 0.9250 - precision: 1.0000 - recall: 0.8500 - val_loss: 0.3206 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 46/60\n",
      "5/5 [==============================] - 94s 20s/step - loss: 0.1868 - accuracy: 0.9250 - precision: 1.0000 - recall: 0.8500 - val_loss: 0.3179 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 47/60\n",
      "5/5 [==============================] - 84s 17s/step - loss: 0.2018 - accuracy: 0.9375 - precision: 1.0000 - recall: 0.8750 - val_loss: 0.3140 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 48/60\n",
      "5/5 [==============================] - 87s 19s/step - loss: 0.1716 - accuracy: 0.9375 - precision: 0.9730 - recall: 0.9000 - val_loss: 0.2959 - val_accuracy: 0.8500 - val_precision: 0.8182 - val_recall: 0.9000\n",
      "Epoch 49/60\n",
      "5/5 [==============================] - 85s 18s/step - loss: 0.1740 - accuracy: 0.9375 - precision: 1.0000 - recall: 0.8750 - val_loss: 0.2848 - val_accuracy: 0.8500 - val_precision: 0.8182 - val_recall: 0.9000\n",
      "Epoch 50/60\n",
      "5/5 [==============================] - 86s 18s/step - loss: 0.1850 - accuracy: 0.9125 - precision: 0.9714 - recall: 0.8500 - val_loss: 0.2669 - val_accuracy: 0.8500 - val_precision: 0.8182 - val_recall: 0.9000\n",
      "Epoch 51/60\n",
      "5/5 [==============================] - 83s 17s/step - loss: 0.1808 - accuracy: 0.9625 - precision: 1.0000 - recall: 0.9250 - val_loss: 0.2965 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 52/60\n",
      "5/5 [==============================] - 84s 18s/step - loss: 0.1683 - accuracy: 0.9500 - precision: 1.0000 - recall: 0.9000 - val_loss: 0.2792 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 53/60\n",
      "5/5 [==============================] - 84s 18s/step - loss: 0.1559 - accuracy: 0.9500 - precision: 1.0000 - recall: 0.9000 - val_loss: 0.2753 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 54/60\n",
      "5/5 [==============================] - 86s 18s/step - loss: 0.1724 - accuracy: 0.9375 - precision: 0.9730 - recall: 0.9000 - val_loss: 0.2842 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 55/60\n",
      "5/5 [==============================] - 83s 17s/step - loss: 0.1653 - accuracy: 0.9750 - precision: 1.0000 - recall: 0.9500 - val_loss: 0.2678 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 56/60\n",
      "5/5 [==============================] - 85s 18s/step - loss: 0.1567 - accuracy: 0.9375 - precision: 1.0000 - recall: 0.8750 - val_loss: 0.2750 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 57/60\n",
      "5/5 [==============================] - 82s 17s/step - loss: 0.1601 - accuracy: 0.9750 - precision: 0.9750 - recall: 0.9750 - val_loss: 0.3195 - val_accuracy: 0.8500 - val_precision: 0.7692 - val_recall: 1.0000\n",
      "Epoch 58/60\n",
      "5/5 [==============================] - 218s 52s/step - loss: 0.1841 - accuracy: 0.9125 - precision: 0.9459 - recall: 0.8750 - val_loss: 0.2856 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 59/60\n",
      "5/5 [==============================] - 81s 17s/step - loss: 0.1688 - accuracy: 0.9500 - precision: 1.0000 - recall: 0.9000 - val_loss: 0.2934 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n",
      "Epoch 60/60\n",
      "5/5 [==============================] - 76s 16s/step - loss: 0.1729 - accuracy: 0.9375 - precision: 1.0000 - recall: 0.8750 - val_loss: 0.2957 - val_accuracy: 0.9000 - val_precision: 0.8333 - val_recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = make_model()\n",
    "\n",
    "model.compile(loss = tf.keras.losses.BinaryCrossentropy(), \n",
    "                optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
    "                metrics = [['accuracy', tf.keras.metrics.Precision(name=\"precision\"), tf.keras.metrics.Recall(name=\"recall\")]])\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    validation_data = (X_test, y_test),\n",
    "                    batch_size = 16,\n",
    "                epochs = 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2558b6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MBNet/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MBNet/assets\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fb198c4bcd0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "model.save(\"MBNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0171e0b3",
   "metadata": {},
   "source": [
    "# save the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
