{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3433bf76",
   "metadata": {
    "id": "162d91e9"
   },
   "source": [
    "# First get all of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be2f7d35",
   "metadata": {
    "id": "75869bdd"
   },
   "outputs": [],
   "source": [
    "# first get all X and y data from the all_points_folds\n",
    "import numpy as np \n",
    "import pickle, random \n",
    "import cv2, os\n",
    "\n",
    "X_all, y = [], []  # X needs to be changed for each fold, y doesn't need to be changed for each fold. \n",
    "\n",
    "for file in os.listdir(\"all_points_folds\"): \n",
    "    with open(f\"all_points_folds/{file}\", 'rb') as f: \n",
    "        X_y = pickle.load(f)\n",
    "        X_all.append(X_y[0])\n",
    "        y.append(X_y[1])\n",
    "\n",
    "        \n",
    "def specify_data(dataset, landmarks): \n",
    "    ds = np.concatenate([X_i for X_i in dataset])\n",
    "    \"\"\"\n",
    "    dataset should contain a 4D matrix of (5, _, 90, 126). \n",
    "    \"\"\" \n",
    "    cols = []\n",
    "    for landmark in landmarks:\n",
    "        cols += (np.array([0, 21, 42, 63, 84, 105]) + landmark).tolist()\n",
    "    \n",
    "    return ds[:, :, tuple(cols)]\n",
    "\n",
    "X_six = specify_data(X_all, [0, 4, 8, 12, 16, 20]).reshape(5, 20, 90, 36)\n",
    "X_one = specify_data(X_all, [0]).reshape(5, 20, 90, 6) # just take the first landmark \n",
    "\n",
    "\n",
    "import random \n",
    "def shuffle(X, y, seed = None):\n",
    "    if seed == None:  \n",
    "        seed = random.randrange(0, 100)\n",
    "        print(f\"using seed {seed}\")\n",
    "    np.random.seed(seed) \n",
    "    new_X = np.concatenate([X_i for X_i in X])\n",
    "    new_y = np.concatenate([y_i for y_i in y])\n",
    "    N = np.random.permutation(new_X.shape[0])\n",
    "    new_X = new_X[N]\n",
    "    new_y = new_y[N]\n",
    "    new_X = new_X.reshape(5, 20, 90, new_X.shape[-1])\n",
    "    new_y = new_y.reshape(5, 20)\n",
    "    return new_X, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f97577f7",
   "metadata": {
    "id": "255dab3c"
   },
   "outputs": [],
   "source": [
    "SEED = 65\n",
    "X_all, y = shuffle(X_all, y, seed = SEED)\n",
    "X_six, _ = shuffle(X_six, y, seed = SEED)\n",
    "X_one, _ = shuffle(X_one, y, seed = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "346f78be",
   "metadata": {
    "id": "a66fe962"
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "def ensemble_val_acc(models, X_tests, y_test): \n",
    "    preds = np.zeros_like(y_test)\n",
    "    for model, X_test in zip(models, X_tests): \n",
    "        preds += model.predict(X_test).flatten() \n",
    "    preds = preds / len(models)\n",
    "    return (np.round_(preds) == y_test).mean(), sklearn.metrics.precision_score(y_test, np.round_(preds)), sklearn.metrics.recall_score(y_test, np.round_(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5be566d2",
   "metadata": {
    "id": "0390341a"
   },
   "outputs": [],
   "source": [
    "import time, glob\n",
    "def cross_validate(make_model_all, make_model_six, make_model_one, X_all, X_six, X_one, y, epochs = 75, callbacks = [], verbose = 1): \n",
    "    val_accuracies, precisions, recalls = [], [], []\n",
    "    for i in range(5): \n",
    "        model_all = make_model_all() \n",
    "        model_six = make_model_six()\n",
    "        model_one = make_model_one() \n",
    "        \n",
    "        # define global labels\n",
    "        y_train = np.concatenate([y_j for j, y_j in enumerate(y) if i != j])\n",
    "        y_test = y[i]\n",
    "        \n",
    "        # first run all \n",
    "        X_test_all = X_all[i]\n",
    "        X_train_all = np.concatenate([X_j for j, X_j in enumerate(X_all) if i != j])\n",
    "        \n",
    "        try:\n",
    "            os.remove(\"best_aso.h5\") \n",
    "        except Exception as e: \n",
    "            pass \n",
    "\n",
    "        # train \n",
    "        history_all = model_all.fit(X_train_all, y_train, validation_data = (X_test_all, y_test), epochs = epochs, callbacks = callbacks, verbose = verbose)\n",
    "        \n",
    "        try: \n",
    "            model_all.load_weights(\"best_aso.h5\")\n",
    "        except Exception as e: \n",
    "            pass\n",
    "        \n",
    "        print(\"\\nevaluation on all:\")\n",
    "        model_all.evaluate(X_test_all, y_test)\n",
    "        \n",
    "        time.sleep(1)\n",
    "        # next train six \n",
    "        \n",
    "        X_test_six = X_six[i]\n",
    "        X_train_six = np.concatenate([X_j for j, X_j in enumerate(X_six) if i != j])\n",
    "        \n",
    "        try:\n",
    "            os.remove(\"best_aso.h5\") \n",
    "        except Exception as e: \n",
    "            pass \n",
    "\n",
    "        # train \n",
    "        history_six = model_six.fit(X_train_six, y_train, validation_data = (X_test_six, y_test), epochs = epochs, callbacks = callbacks, verbose = verbose)\n",
    "        \n",
    "        try: \n",
    "            model_six.load_weights(\"best_aso.h5\")\n",
    "        except Exception as e: \n",
    "            pass\n",
    "        \n",
    "        print(\"\\nevaluation on six:\")\n",
    "        model_six.evaluate(X_test_six, y_test)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # next train one\n",
    "        X_test_one = X_one[i]\n",
    "        X_train_one = np.concatenate([X_j for j, X_j in enumerate(X_one) if i != j])\n",
    "        \n",
    "        try: \n",
    "            os.remove(\"best_aso.h5\")\n",
    "        except Exception as e: \n",
    "            pass \n",
    "    \n",
    "        # train this model \n",
    "        history_one = model_one.fit(X_train_one, y_train, validation_data = (X_test_one, y_test), epochs = epochs, callbacks = callbacks, verbose = verbose)\n",
    "        \n",
    "        try: \n",
    "            model_six.load_weights(\"best_aso.h5\")\n",
    "        except Exception as e: \n",
    "            pass\n",
    "        \n",
    "        print(\"\\nevaluation on one:\")\n",
    "        model_one.evaluate(X_test_one, y_test)\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # YAY! WE HAVE TRAINED THE MODEL ON EVERYTHING FOR THIS FOLD\n",
    "    \n",
    "        # get the aggregate validation accuracy on everything\n",
    "        models = [model_all, model_six, model_one]\n",
    "        val_acc, pres, recall = ensemble_val_acc(models, [X_test_all, X_test_six, X_test_one], y_test)\n",
    "        val_accuracies.append(val_acc)\n",
    "        precisions.append(pres)\n",
    "        recalls.append(recall)\n",
    "        print(f\"ensemble validation accuracy : {(val_acc, pres, recall)}\")\n",
    "        time.sleep(2)\n",
    "\n",
    "        for video in glob.glob(\"*mov\"): \n",
    "            print(f\"video is {video}, {predict_on_video(models, video)}\")\n",
    "    print(f\"average : {sum(val_accuracies) / len(val_accuracies), sum(precisions) / len(precisions), sum(recalls) / len(recalls)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea88eaa4",
   "metadata": {
    "id": "7c02d84d"
   },
   "outputs": [],
   "source": [
    "# create the functions to create models \n",
    "import tensorflow as tf \n",
    "def make_model_all(): \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.LSTM(64, return_sequences=False), \n",
    "        tf.keras.layers.Dropout(0.3), \n",
    "        tf.keras.layers.Dense(1, activation = \"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def make_model_six(): \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.LSTM(64, return_sequences=False, input_shape = (None, 36)), \n",
    "        tf.keras.layers.Dropout(0.3), \n",
    "        tf.keras.layers.Dense(1, activation = 'sigmoid') \n",
    "    ]) \n",
    "\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = tf.keras.optimizers.Adam(learning_rate=0.01), metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "    return model\n",
    "\n",
    "def make_model_one(): \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.LSTM(32, return_sequences=False), \n",
    "        tf.keras.layers.Dropout(0.2), \n",
    "        tf.keras.layers.Dense(1, activation = \"sigmoid\")\n",
    "    ])\n",
    "    \n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = tf.keras.optimizers.Adam(learning_rate=0.01), metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d6c9965",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4da2ec83",
    "outputId": "23d4a2a5-a369-4966-b529-0fefac2595d2"
   },
   "outputs": [],
   "source": [
    "import mediapipe as mp \n",
    "from tqdm import tqdm \n",
    "def hand_locations_general(frame, min_detection_confidence = 0.5, min_tracking_confidence = 0.5): \n",
    "    \"\"\"give all landmarks\"\"\"\n",
    "\n",
    "    hands = mp.solutions.hands.Hands(min_detection_confidence=min_detection_confidence, min_tracking_confidence=min_tracking_confidence) # MAKE SURE THIS IS ALL GOOD \n",
    "    results = hands.process(frame.astype('uint8'))\n",
    "    X_locations = [0] * 42\n",
    "    Y_locations = [0] * 42\n",
    "    Z_locations = [0] * 42\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        x = y = z = 0 \n",
    "        for hand, hand_landmark in enumerate(results.multi_hand_landmarks):\n",
    "            for i in range(0, 21):\n",
    "                landmark = hand_landmark.landmark[i]\n",
    "                X_locations[x] = landmark.x\n",
    "                Y_locations[y] = landmark.y \n",
    "                Z_locations[z] = landmark.z\n",
    "                x += 1; y += 1; z +=1; \n",
    "            \n",
    "    hands.close()\n",
    "    return np.concatenate([X_locations, Y_locations, Z_locations]) \n",
    "\n",
    "\n",
    "# create a function to pad your videos \n",
    "def pad(locations, maxlen = 90, padding = \"post\", truncating = \"post\"): \n",
    "    new_locations = locations.tolist() \n",
    "    empty_row = np.zeros((1, 126))\n",
    "    for i, video in tqdm(enumerate(new_locations)): \n",
    "        if len(video) < maxlen:  \n",
    "            for new_row in range(maxlen - len(video)): \n",
    "                if padding == \"post\": \n",
    "                    new_locations[i] = np.array(new_locations[i])\n",
    "                    new_locations[i] = np.concatenate([new_locations[i], empty_row])\n",
    "                if padding == \"pre\": \n",
    "                    new_locations[i] = np.array(new_locations[i])\n",
    "                    new_locations[i] = np.concatenate([empty_row, new_locations[i]])\n",
    "\n",
    "        if len(video) > maxlen: \n",
    "            if truncating == \"post\": \n",
    "                new_locations[i] = new_locations[i][:maxlen]\n",
    "            elif truncating == \"pre\": \n",
    "                new_locations[i] = new_locations[i][len(video) - maxlen : ]\n",
    "    return np.array(new_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a390a16",
   "metadata": {
    "id": "64da9ea0"
   },
   "outputs": [],
   "source": [
    "import mediapipe as mp \n",
    "from tqdm import tqdm \n",
    "def hand_locations_general(frame, min_detection_confidence = 0.5, min_tracking_confidence = 0.5): \n",
    "    \"\"\"give all landmarks\"\"\"\n",
    "\n",
    "    hands = mp.solutions.hands.Hands(min_detection_confidence=min_detection_confidence, min_tracking_confidence=min_tracking_confidence) # MAKE SURE THIS IS ALL GOOD \n",
    "    results = hands.process(frame.astype('uint8'))\n",
    "    X_locations = [0] * 42\n",
    "    Y_locations = [0] * 42\n",
    "    Z_locations = [0] * 42\n",
    "        \n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        x = y = z = 0 \n",
    "        for hand, hand_landmark in enumerate(results.multi_hand_landmarks):\n",
    "            for i in range(0, 21):\n",
    "                landmark = hand_landmark.landmark[i]\n",
    "                X_locations[x] = landmark.x\n",
    "                Y_locations[y] = landmark.y \n",
    "                Z_locations[z] = landmark.z\n",
    "                x += 1; y += 1; z +=1; \n",
    "            \n",
    "    hands.close()\n",
    "    return np.concatenate([X_locations, Y_locations, Z_locations]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dedbbdbf",
   "metadata": {
    "id": "4qDuUuABWpJr"
   },
   "outputs": [],
   "source": [
    "model_to_arrangements = {1 : list(range(21)), 2 : [0, 4, 8, 12, 16, 20], 3 : [0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4d11714",
   "metadata": {
    "id": "ms0s-2miWlb0"
   },
   "outputs": [],
   "source": [
    "# function to ensemble predict on frames. \n",
    "def ensemble_predict(models, X_test):\n",
    "    preds = np.zeros((X_test.shape[0], 1))\n",
    "    for model, landmarks in tqdm(zip(models, model_to_arrangements.values())):\n",
    "        test_data = specify_data(np.array([X_test]), landmarks)\n",
    "        preds += model.predict(test_data)\n",
    "    preds = preds / len(models)\n",
    "    return preds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fff18d3",
   "metadata": {
    "id": "4de0a3df"
   },
   "outputs": [],
   "source": [
    "# create a function to then predict on videos \n",
    "import cv2, numpy as np\n",
    "def predict_on_video(models, path): \n",
    "    LOCATIONS = []\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    while cap.isOpened():\n",
    "        _, frame = cap.read()\n",
    "        if not _: break \n",
    "\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        LOCATIONS.append(hand_locations_general(frame))\n",
    "    \n",
    "    print('read all locations')\n",
    "    LOCATIONS = np.array([LOCATIONS])\n",
    "    LOCATIONS = pad(LOCATIONS)\n",
    "    print(\"padded\")\n",
    "    return ensemble_predict(models, LOCATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df75b9d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a19a5cd5",
    "outputId": "dee9a319-5d55-4c2e-f9a3-4ee41ad95b7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "evaluation on all:\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5952 - accuracy: 0.6500 - precision_15: 0.5455 - recall_15: 0.7500\n",
      "\n",
      "evaluation on six:\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6795 - accuracy: 0.7500 - precision_16: 0.8000 - recall_16: 0.5000\n",
      "\n",
      "evaluation on one:\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5655 - accuracy: 0.7000 - precision_17: 0.6667 - recall_17: 0.5000\n",
      "ensemble validation accuracy : (0.75, 0.7142857142857143, 0.625)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 20360.70it/s]\n",
      "3it [00:00, 28.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is armflapping_1.mov, [0.48496411]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 8630.26it/s]\n",
      "3it [00:00, 31.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is armflapping_3.mov, [0.49069432]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 18893.26it/s]\n",
      "3it [00:00, 31.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is armflapping_2.mov, [0.44075563]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 20068.44it/s]\n",
      "3it [00:00, 31.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is control_1.mov, [0.42073368]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 14665.40it/s]\n",
      "3it [00:00, 32.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is control_2.mov, [0.66578533]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 13148.29it/s]\n",
      "3it [00:00, 31.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is control_3.mov, [0.43558948]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "evaluation on all:\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6253 - accuracy: 0.7000 - precision_18: 0.8182 - recall_18: 0.6923\n",
      "\n",
      "evaluation on six:\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9339 - accuracy: 0.6000 - precision_19: 0.8571 - recall_19: 0.4615\n",
      "\n",
      "evaluation on one:\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6283 - accuracy: 0.7000 - precision_20: 0.8182 - recall_20: 0.6923\n",
      "ensemble validation accuracy : (0.6, 0.7777777777777778, 0.5384615384615384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 14926.35it/s]\n",
      "3it [00:00, 32.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is armflapping_1.mov, [0.19934576]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 6543.38it/s]\n",
      "3it [00:00, 26.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is armflapping_3.mov, [0.39950474]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 16384.00it/s]\n",
      "3it [00:00, 29.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is armflapping_2.mov, [0.20237013]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 15887.52it/s]\n",
      "3it [00:00, 30.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is control_1.mov, [0.21193133]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 16710.37it/s]\n",
      "3it [00:00, 27.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is control_2.mov, [0.70189082]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 12985.46it/s]\n",
      "3it [00:00, 23.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is control_3.mov, [0.20377976]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "evaluation on all:\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6424 - accuracy: 0.6500 - precision_21: 0.6429 - recall_21: 0.8182\n",
      "\n",
      "evaluation on six:\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7856 - accuracy: 0.7000 - precision_22: 0.6923 - recall_22: 0.8182\n",
      "\n",
      "evaluation on one:\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7164 - accuracy: 0.6500 - precision_23: 0.7000 - recall_23: 0.6364\n",
      "ensemble validation accuracy : (0.65, 0.6666666666666666, 0.7272727272727273)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 16912.52it/s]\n",
      "3it [00:00, 28.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is armflapping_1.mov, [0.5044913]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 7084.97it/s]\n",
      "3it [00:00, 26.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is armflapping_3.mov, [0.45500755]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 14716.86it/s]\n",
      "3it [00:00, 29.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is armflapping_2.mov, [0.49416524]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 18477.11it/s]\n",
      "3it [00:00, 30.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is control_1.mov, [0.21085004]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 16912.52it/s]\n",
      "3it [00:00, 31.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is control_2.mov, [0.81064153]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 12192.74it/s]\n",
      "3it [00:00, 30.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is control_3.mov, [0.55044185]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "evaluation on all:\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5088 - accuracy: 0.7500 - precision_24: 0.7273 - recall_24: 0.8000\n",
      "\n",
      "evaluation on six:\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5443 - accuracy: 0.8500 - precision_25: 0.8182 - recall_25: 0.9000\n",
      "\n",
      "evaluation on one:\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5974 - accuracy: 0.5500 - precision_26: 0.5333 - recall_26: 0.8000\n",
      "ensemble validation accuracy : (0.85, 0.8181818181818182, 0.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 19878.22it/s]\n",
      "3it [00:00, 33.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is armflapping_1.mov, [0.31222388]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 5737.76it/s]\n",
      "3it [00:00, 31.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is armflapping_3.mov, [0.48356748]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 16912.52it/s]\n",
      "3it [00:00, 29.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is armflapping_2.mov, [0.2369801]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 17848.10it/s]\n",
      "3it [00:00, 29.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is control_1.mov, [0.24133052]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 17331.83it/s]\n",
      "3it [00:00, 28.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is control_2.mov, [0.65813792]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 15650.39it/s]\n",
      "3it [00:00, 30.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is control_3.mov, [0.23912502]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "evaluation on all:\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.8170 - accuracy: 0.7000 - precision_27: 0.6000 - recall_27: 0.7500\n",
      "\n",
      "evaluation on six:\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7386 - accuracy: 0.7000 - precision_28: 0.6250 - recall_28: 0.6250\n",
      "\n",
      "evaluation on one:\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6978 - accuracy: 0.6500 - precision_29: 0.5556 - recall_29: 0.6250\n",
      "ensemble validation accuracy : (0.7, 0.6, 0.75)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 19239.93it/s]\n",
      "3it [00:00, 31.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is armflapping_1.mov, [0.39668499]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 6374.32it/s]\n",
      "3it [00:00, 31.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is armflapping_3.mov, [0.49038376]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 16912.52it/s]\n",
      "3it [00:00, 28.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is armflapping_2.mov, [0.37465074]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 1897.02it/s]\n",
      "3it [00:00, 29.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is control_1.mov, [0.26120852]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 20068.44it/s]\n",
      "3it [00:00, 31.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is control_2.mov, [0.76625997]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 15363.75it/s]\n",
      "3it [00:00, 30.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read all locations\n",
      "padded\n",
      "video is control_3.mov, [0.29201673]\n",
      "average : (0.71, 0.7153823953823955, 0.7081468531468531)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"best_aso.h5\", save_best_only=True, monitor = \"val_accuracy\")\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = \"val_accuracy\", patience=10)\n",
    "cross_validate(make_model_all, make_model_six, make_model_one, X_all, X_six, X_one, y, epochs = 75, callbacks=[checkpoint, early_stopping], verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306e4603",
   "metadata": {
    "id": "472d64c2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "all_six_one_ensemble.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
